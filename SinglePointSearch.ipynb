{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "from sqlalchemy import Column, Integer, Text, ForeignKey,String,Table, DateTime\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from operator import attrgetter\n",
    "import math\n",
    "import statistics\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from platform import python_version\n",
    "import import_ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import pertubativeHeuristics\n",
    "from pertubativeHeuristics import pertubativeHeuristic, createSolution,genInitialSolution, EvaluateSolution,populateDB,getCurrentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"test.exam\"\n",
    "sample_one_early =\"./itc2007_dataset/exam_comp_set4.exam\" #done\n",
    "sample_two_early =\"./itc2007_dataset/exam_comp_set1.exam\" #done\n",
    "\n",
    "sample_one_late = \"./itc2007_dataset/exam_comp_set6.exam\"#done\n",
    "sample_two_late = \"./itc2007_dataset/exam_comp_set8.exam\"#done\n",
    "\n",
    "\n",
    "sample_one_hidden = \"./itc2007_dataset/exam_comp_set9.exam\"#done\n",
    "sample_two_hidden = \"./itc2007_dataset/exam_comp_set12.exam\"#done\n",
    "\n",
    "sample = sample_one_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = db.create_engine('postgresql://postgres:password@postgres:5432/postgres')\n",
    "engine = db.create_engine('postgresql://postgres:password@postgres:5432/postgres')\n",
    "connection = engine.connect()\n",
    "meta = db.MetaData(connection)\n",
    "Base = declarative_base()\n",
    "Session = sessionmaker(bind = engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softconstraints,constraints,examRows,periodRows,period_count = populateDB(engine,session,Base,connection,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genInitialSolution(connection,session,constraints,examRows,periodRows,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentScore = getCurrentScore(softconstraints,connection)\n",
    "currentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(index, utility_scores):\n",
    "    utility_scores[index-1]  = utility_scores[index-1] + 0.5\n",
    "def punish(index, utility_scores):\n",
    "    utility_scores[index-1]  = utility_scores[index-1] - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    iteration_scores = []\n",
    "    utility_Scores = [1,1,1,1,1,1,1,1,1]\n",
    "    \n",
    "    currentScore = getCurrentScore(softconstraints,connection)\n",
    "    violationCount = EvaluateSolution(softconstraints,connection)\n",
    "    \n",
    " \n",
    "    \n",
    "    quality_lower_bound = currentScore\n",
    "    for i in range(50):\n",
    "        heuristic= utility_Scores.index(max(utility_Scores)) + 1\n",
    "        \n",
    "        \n",
    "        indices = [i for i, x in enumerate(utility_Scores) if x == max(utility_Scores)]\n",
    "#         print(\"indices:\",indices)\n",
    "        if len(indices) > 1:\n",
    "            heuristic = random.choice(indices)\n",
    "   \n",
    "        pertubativeHeuristic(heuristic,period_count,connection)\n",
    "        score = getCurrentScore(softconstraints,connection)\n",
    "        iteration_scores.append(score)\n",
    "        violationCount = EvaluateSolution(constraints,connection)\n",
    "\n",
    "\n",
    "        if violationCount > 0:\n",
    "            rollback_query = db.text(\"rollback to pre_heuristic;\")\n",
    "            connection.execute(rollback_query)\n",
    "            violationCount = EvaluateSolution(constraints,connection)        \n",
    "        elif score < currentScore and violationCount == 0:\n",
    "            reward(heuristic,utility_Scores)\n",
    "            currentScore = score\n",
    "\n",
    "\n",
    "        elif violationCount == 0 and score > currentScore:\n",
    "            punish(heuristic,utility_Scores)\n",
    "            # the threshold decreases\n",
    "            if score < quality_lower_bound + (currentScore - quality_lower_bound)*(1 - i/50):\n",
    "                         currentScore = score\n",
    "            else:\n",
    "                rollback_query = db.text(\"rollback to pre_heuristic;\")\n",
    "                connection.execute(rollback_query)\n",
    "                \n",
    "    run_scores.append(iteration_scores)\n",
    "    commit_query = db.text(\"rollback work;\")\n",
    "    connection.execute(commit_query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in run_scores:\n",
    "    score.insert(0,currentScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(run_scores[1],label='run 1')\n",
    "plt.plot(run_scores[2],label='run 2')\n",
    "plt.plot(run_scores[3],label='run 3')\n",
    "plt.plot(run_scores[4], label='run 4')\n",
    "plt.plot(run_scores[5], label='run 5')\n",
    "plt.plot(run_scores[5], label='run 6')\n",
    "\n",
    "\n",
    "plt.ylabel('objective score')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend();\n",
    "\n",
    "plt.title(\"exam set 6 single point search runs\")\n",
    "plt.show()\n",
    "# fig.savefig('./ass2Results/exam_set_6_single-point-search-runs.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in run_scores:\n",
    "    temp = np.asarray(score)\n",
    "    new_scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = run_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_arr = np.asarray(scores)\n",
    "scores_arr =  scores_arr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"result for :\", sample)\n",
    "# print(\"Objective scores:\",scores)\n",
    "print(\"mean:\",np.mean(scores_arr))\n",
    "print(\"std:\",np.std(new_scores))\n",
    "print (\"min:\",np.min(scores_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
